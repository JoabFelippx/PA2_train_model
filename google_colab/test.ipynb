{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/JoabFelippx/PA2_train_model.git"
      ],
      "metadata": {
        "id": "iTEAEmSXwoum"
      },
      "id": "iTEAEmSXwoum",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/PA2_train_model/requirements.txt"
      ],
      "metadata": {
        "id": "Ri2iQrIdwol5"
      },
      "id": "Ri2iQrIdwol5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o /content/PA2_train_model/dataset.zip -d /content/"
      ],
      "metadata": {
        "id": "UoTgGixZwui_"
      },
      "id": "UoTgGixZwui_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d1639f5",
      "metadata": {
        "id": "3d1639f5"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ca45d6f",
      "metadata": {
        "id": "9ca45d6f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import cv2 as cv\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8649166",
      "metadata": {
        "id": "f8649166"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import load_img, img_to_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c8b69a1",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "6c8b69a1"
      },
      "outputs": [],
      "source": [
        "from random import shuffle\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c553ed32",
      "metadata": {
        "id": "c553ed32"
      },
      "outputs": [],
      "source": [
        "# size of the image\n",
        "TGSIZE = (224, 224)\n",
        "input_shape = (224, 224, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c73d0c39",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "c73d0c39"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/dataset' # path to the dataset folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b894fc8",
      "metadata": {
        "id": "7b894fc8"
      },
      "outputs": [],
      "source": [
        "train_dir = f'{dataset_path}/train'\n",
        "valid_dir = f'{dataset_path}/valid'\n",
        "test_dir = f'{dataset_path}/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a837501",
      "metadata": {
        "id": "7a837501"
      },
      "outputs": [],
      "source": [
        "train_junior_dir = os.path.join(train_dir, 'junior')\n",
        "train_gustavo_dir = os.path.join(train_dir, 'gustavo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77f04f39",
      "metadata": {
        "id": "77f04f39"
      },
      "outputs": [],
      "source": [
        "valid_junior_dir = os.path.join(valid_dir, 'junior')\n",
        "valid_gustavo_dir = os.path.join(valid_dir, 'gustavo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95918246",
      "metadata": {
        "id": "95918246"
      },
      "outputs": [],
      "source": [
        "test_junior_dir = os.path.join(test_dir, 'junior')\n",
        "test_gustavo_dir = os.path.join(test_dir, 'gustavo')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ea40435",
      "metadata": {
        "id": "7ea40435"
      },
      "source": [
        "train and validation generator with data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0159379",
      "metadata": {
        "id": "e0159379"
      },
      "outputs": [],
      "source": [
        "def train_valid_generator(train_dir, valid_dir):\n",
        "\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, horizontal_flip=True, fill_mode='nearest')\n",
        "    valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(train_dir, target_size=TGSIZE, batch_size=20, class_mode='binary')\n",
        "    valid_generator = valid_datagen.flow_from_directory(valid_dir, target_size=TGSIZE, batch_size=20, class_mode='binary')\n",
        "\n",
        "    return train_generator, valid_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ee1357e",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "1ee1357e"
      },
      "outputs": [],
      "source": [
        "train_generator, valid_generator = train_valid_generator(train_dir, valid_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09d18d97",
      "metadata": {
        "id": "09d18d97"
      },
      "outputs": [],
      "source": [
        "# load the VGG16 model\n",
        "def create_pretrained_model():\n",
        "\n",
        "    pre_trained_model_vgg16 = VGG16(input_shape=input_shape, weights=None, include_top=False)\n",
        "\n",
        "    for layer in pre_trained_model_vgg16.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    return pre_trained_model_vgg16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e010f968",
      "metadata": {
        "id": "e010f968"
      },
      "outputs": [],
      "source": [
        "pre_trained_model_vgg16 = create_pretrained_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c82b553",
      "metadata": {
        "id": "0c82b553"
      },
      "outputs": [],
      "source": [
        "# show the model summary\n",
        "pre_trained_model_vgg16.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57aed2d9",
      "metadata": {
        "id": "57aed2d9"
      },
      "outputs": [],
      "source": [
        "# callback to stop the training when the accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "    if(logs.get('accuracy')>0.999):\n",
        "      print(\"\\nAtingi 99,9% de precisÃ£o, portanto, estou cancelando o treinamento!!\")\n",
        "      self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a5f014",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "81a5f014"
      },
      "outputs": [],
      "source": [
        "# output of the last layer of the VGG16 model\n",
        "def output_last_layer(pre_trained_model_vgg16):\n",
        "\n",
        "    last_layer = pre_trained_model_vgg16.get_layer('block5_pool')\n",
        "    last_output = last_layer.output\n",
        "\n",
        "    return last_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ed364a",
      "metadata": {
        "id": "d7ed364a"
      },
      "outputs": [],
      "source": [
        "last_output = output_last_layer(pre_trained_model_vgg16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78113cd5",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "78113cd5"
      },
      "outputs": [],
      "source": [
        "# create the final model\n",
        "def create_final_model(pre_trained_model_vgg16, last_output):\n",
        "\n",
        "    x = tf.keras.layers.Flatten()(last_output)\n",
        "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    x = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(pre_trained_model_vgg16.input, x)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a23e1a8",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "5a23e1a8"
      },
      "outputs": [],
      "source": [
        "model = create_final_model(pre_trained_model_vgg16, last_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ffa8836",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "4ffa8836"
      },
      "outputs": [],
      "source": [
        "model.load_weights('model_weight.h5') # PEGAR OS PESOS NO DRIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59af756d",
      "metadata": {
        "id": "59af756d"
      },
      "outputs": [],
      "source": [
        "test_images = [f'{test_junior_dir}/{img}' for img in os.listdir(test_junior_dir)] + [f'{test_gustavo_dir}/{img}' for img in os.listdir(test_gustavo_dir)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c20b67c",
      "metadata": {
        "id": "7c20b67c"
      },
      "outputs": [],
      "source": [
        "shuffle(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb7e606b",
      "metadata": {
        "id": "eb7e606b"
      },
      "outputs": [],
      "source": [
        "for img_path in test_images:\n",
        "    loaded_img = load_img(img_path, target_size=TGSIZE)\n",
        "\n",
        "    img_array = img_to_array(loaded_img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "    model_prediction = model.predict(img_array)\n",
        "    print(model_prediction)\n",
        "\n",
        "    if model_prediction[0][0] > 0.5:\n",
        "        print(f'Gustavo: {model_prediction[0][0]}\\timage: {img_path}')\n",
        "    elif model_prediction[0][1] > 0.5:\n",
        "        print(f'Junior: {model_prediction[0][1]}\\timage: {img_path}')\n",
        "\n",
        "    # if runing code outside of jupyter notebook, uncomment the following lines\n",
        "    # cv.imshow('image', cv.imread(img_path))\n",
        "    # cv.waitKey(0)\n",
        "    # cv.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}